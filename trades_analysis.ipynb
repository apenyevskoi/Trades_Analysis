{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c13dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as sm\n",
    "df = pd.read_csv('market_logs.log', sep = ',', header = None, names = ['one', 'two', 'three'])\n",
    "df1 = pd.read_csv('exec_logs.log', sep = ',', header = None, names = ['one', 'two', 'three', 'four', 'five', 'six'])\n",
    "\n",
    "#PRIMARY DATA SORTING OUT\n",
    "\n",
    "#market_logs.log data sorting out\n",
    "market_df = pd.DataFrame( \n",
    "  { 'time' :      [ x.strip().split(' ')[4] for x in df['one'] ],\n",
    "    'direction' : [ x.strip().split(' ')[7] for x in df['one'] ],\n",
    "    'price' :     [ x.strip().split(' ')[1] for x in df['two'] ],\n",
    "    'volume' :    [ x.strip().split(' ')[2] for x in df['three'] ],\n",
    "    'vol_bid' :   [ x.strip().split('@')[0] \n",
    "                      for x in [ x.strip().split(' ')[6] \n",
    "                                for x in df['three'] ]],\n",
    "    'pric_bid' :    [ x.strip().split('x')[0] \n",
    "                     for x in [ x.strip().split('@')[1]   \n",
    "                      for x in [ x.strip().split(' ')[6] \n",
    "                                for x in df['three'] ] ] ],\n",
    "    'pric_ask' :   [ x.strip().split('x')[1] \n",
    "                     for x in [ x.strip().split('@')[1]  \n",
    "                      for x in [ x.strip().split(' ')[6] \n",
    "                                for x in df['three'] ] ] ],\n",
    "    'vol_ask' :    [ x.strip().split('@')[2] \n",
    "                      for x in [ x.strip().split(' ')[6] \n",
    "                                for x in df['three'] ] ] }\n",
    "                  )\n",
    "#convert to correct data type\n",
    "market_df.time = pd.to_numeric(market_df.time)\n",
    "market_df.time = pd.to_datetime(market_df.time, unit = 'ns')\n",
    "market_df.direction = pd.to_numeric(market_df.direction)\n",
    "market_df.price = pd.to_numeric(market_df.price)\n",
    "market_df.volume = pd.to_numeric(market_df.volume)\n",
    "market_df.vol_bid = pd.to_numeric(market_df.vol_bid)\n",
    "market_df.pric_bid = pd.to_numeric(market_df.pric_bid)\n",
    "market_df.pric_ask = pd.to_numeric(market_df.pric_ask)\n",
    "market_df.vol_ask = pd.to_numeric(market_df.vol_ask)\n",
    "#split 'time' to date,hour,minute etc.\n",
    "market_df[ 'date' ] = market_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[0] ) )\n",
    "market_df[ 'date' ] = pd.to_datetime(market_df[ 'date' ])\n",
    "market_df[ 'hour' ] = market_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[1].split(':')[0] ) ).astype(int)\n",
    "market_df[ 'minute' ] = market_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[1].split(':')[1] ) ).astype(int)\n",
    "market_df[ 'second' ] = market_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[1].split(':')[2].split('.')[0] ) ).astype(int)\n",
    "market_df[ 'millisec' ] = market_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split('.')[1][0:3:1] ) ).astype(int)\n",
    "market_df[ 'microsec' ] = market_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split('.')[1][3:6:1] ) ).astype(int)\n",
    "market_df[ 'nanosec' ] = market_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split('.')[1][6:9:1] ) ).astype(int)\n",
    "\n",
    "#exec_logs.log data sorting out\n",
    "orders_df = pd.DataFrame( \n",
    "  { 'time' :      [ x.strip().split(' ')[4] for x in df1['one'] ],\n",
    "    'id' :        [ x.strip().split(' ')[7] for x in df1['one'] ],\n",
    "    'side' :      [ x.strip().split(' ')[1] for x in df1['two'] ],\n",
    "    'price' :     [ x.strip().split(' ')[1] for x in df1['three'] ],\n",
    "    'volume' :    [ x.strip().split(' ')[2] for x in df1['four'] ],\n",
    "    'volume_left':[ x.strip().split(' ')[4] for x in df1['five'] ],\n",
    "    'delta_exec' :[ x.strip().split(' ')[1] for x in df1['six'] ]\n",
    "     }\n",
    "                  )\n",
    "#convert to correct data type\n",
    "orders_df.time = pd.to_numeric(orders_df.time)\n",
    "orders_df.time = pd.to_datetime(orders_df.time, unit = 'ns')\n",
    "orders_df.id = pd.to_numeric(orders_df.id)\n",
    "orders_df.side = pd.to_numeric(orders_df.side)\n",
    "orders_df.price = pd.to_numeric(orders_df.price)\n",
    "orders_df.volume = pd.to_numeric(orders_df.volume)\n",
    "orders_df.volume_left = pd.to_numeric(orders_df.volume_left)\n",
    "orders_df.delta_exec = pd.to_numeric(orders_df.delta_exec)\n",
    "#split 'time' to date,hour,minute etc.\n",
    "orders_df[ 'date' ] = orders_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[0] ) )\n",
    "orders_df[ 'date' ] = pd.to_datetime(orders_df[ 'date' ])\n",
    "orders_df[ 'hour' ] = orders_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[1].split(':')[0] ) ).astype(int)\n",
    "orders_df[ 'minute' ] = orders_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[1].split(':')[1] ) ).astype(int)\n",
    "orders_df[ 'second' ] = orders_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split(' ')[1].split(':')[2].split('.')[0] ) ).astype(int)\n",
    "orders_df[ 'millisec' ] = orders_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split('.')[1][0:3:1] ) ).astype(int)\n",
    "orders_df[ 'microsec' ] = orders_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split('.')[1][3:6:1] ) ).astype(int)\n",
    "orders_df[ 'nanosec' ] = orders_df[ 'time' ].astype( str ).map( lambda s: ''.join( s.split('.')[1][6:9:1] ) ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b261d6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation b/n delta_exec and dmin5\n",
      " 0.01187651156663576\n"
     ]
    }
   ],
   "source": [
    "#TASK 2.2\n",
    "#GENERAL PART\n",
    "#merge market and exec tables, calculation of dmin5 column and correlation\n",
    "market_without_5sec = market_df.loc [ market_df['time'] >= market_df['time'][0] + pd.Timedelta('5 seconds') ]\n",
    "markets_orders = pd.merge(market_without_5sec, orders_df, how = 'right', on = ('date', 'hour','minute') )\n",
    "markets_orders = markets_orders.drop_duplicates(subset = ['id'])\n",
    "markets_orders = markets_orders.reset_index(drop = True)\n",
    "markets_orders = markets_orders.assign( dmin5 = ( ( ( ( markets_orders.pric_bid + \n",
    "                                           markets_orders.pric_bid ) /2 ) - \n",
    "                                      markets_orders.price_y ) * markets_orders.side ) )\n",
    "\n",
    "print('Correlation b/n delta_exec and dmin5\\n',markets_orders.corr().unstack()['delta_exec'].iloc[23])\n",
    "#answer: corr(dmin5, delta_exec) = 0.011877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 2.1\n",
    "\n",
    "#Researching of market trades\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd774d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROFIT/LOSS\n",
    "#profit/loss result for period\n",
    "#quantity of +/- trades\n",
    "#close_trade.to_list() - open_trade.to_list()\n",
    "\n",
    "############data sorting out\n",
    "df = markets_orders\n",
    "open_trade = ( df[::2]['price_y'] * df[::2]['volume_y'] * df[::2]['side'] ).reset_index(drop = True)\n",
    "close_trade = ( df[1::2]['price_y'] * df[1::2]['volume_y'] * df[1::2]['side']).reset_index(drop = True)\n",
    "side_trade = df[::2]['side'].reset_index(drop = True)\n",
    "week_day = df[::2]['time_y'].apply(lambda x: x.weekday()).reset_index(drop = True)\n",
    "hour_trade = df[::2]['time_y'].dt.hour.reset_index(drop = True)\n",
    "vol_left_op = df[::2]['volume_left'].reset_index(drop = True)\n",
    "vol_left_cl = df[::2]['volume_left'].reset_index(drop = True)\n",
    "pos_time = df[1::2]['time_y'].reset_index(drop = True) - df[::2]['time_y'].reset_index(drop = True)\n",
    "summary_data = pd.DataFrame( {'open' : open_trade, \n",
    "                            'close' : close_trade, \n",
    "                            'side' : side_trade,\n",
    "                            'week_day' : week_day,\n",
    "                            'hour_trade' : hour_trade,\n",
    "                            'vol_left_op' : vol_left_op,\n",
    "                            'vol_left_cl' : vol_left_cl,\n",
    "                             'pos_time' : pos_time} )\n",
    "summary_data = summary_data.assign(prof_loss = (-summary_data.close - summary_data.open) )\n",
    "summary_data['pos_neg'] = pd.cut( summary_data['prof_loss'], \n",
    "        [-np.inf, -0.01, 0.01, np.inf], \n",
    "        labels = ['pos','zero','neg'] )\n",
    "#open - buy price\n",
    "#close - sell price\n",
    "#side - long/short\n",
    "#week_day - day of the week the trade was executed\n",
    "#hour_trade - hour of the day the trade was executed\n",
    "#vol_left_op - volume left after trade opening\n",
    "#vol_left_cl- volume left after trade closing\n",
    "#prof_loss - financial result of the trade\n",
    "#pos_neg - profit, neutral or loss of trade\n",
    "#pos_time - time which continues in the trade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0762ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Trade Result -29.8\n",
      "\n",
      "2.Profit Factor 0.91\n",
      "\n",
      "3.Quantity of trades\n",
      "           trades\n",
      "positive    1332\n",
      "neutral      936\n",
      "negative    2073\n",
      "\n",
      "4.Long/Short Trades \n",
      " long 2462                  \n",
      "   positive   759\n",
      "   neutral    537\n",
      "   negative  1166 \n",
      " short 1879                 \n",
      "   positive  573\n",
      "   neutral   399\n",
      "   negative  907\n",
      "\n",
      "5.Trades by day of the week\n",
      " Monday        822\n",
      "Tuesday       854\n",
      "Wednesday     794\n",
      "Thursday      798\n",
      "Friday       1073\n",
      "Name: trades, dtype: int64\n",
      "week_day  Monday  Tuesday  Wednesday  Thursday  Friday\n",
      "pos_neg                                               \n",
      "pos          245      287        224       248     328\n",
      "zero         173      160        184       181     238\n",
      "neg          404      407        386       369     507\n",
      "\n",
      "6. Trades by hour of day\n",
      "    hour_trade  trades\n",
      "0           0    1105\n",
      "1           1     815\n",
      "2           2     623\n",
      "3           3     482\n",
      "4           4     409\n",
      "5           5     576\n",
      "6           6     331\n",
      "hour_trade    0    1    2    3    4    5    6\n",
      "pos_neg                                      \n",
      "pos         344  231  172  172  137  168  108\n",
      "zero        234  173  142  103   90  131   63\n",
      "neg         527  411  309  207  182  277  160\n",
      "\n",
      "7. Time in the Trades\n",
      "\n",
      "Mean Time in the position\n",
      " mean    0 days 00:02:18.398076320\n",
      "min     0 days 00:00:00.003800001\n",
      "max     0 days 00:55:34.672947800\n",
      "Name: pos_time, dtype: object\n",
      "\n",
      "Mean Time in the position of Negative Trades\n",
      " 0 days 00:01:31.962369352\n",
      "Mean Time in the position of Positive Trades\n",
      " 0 days 00:03:41.599496381\n"
     ]
    }
   ],
   "source": [
    "#TASK 2.1\n",
    "##GENERAL PART\n",
    "#Data for Researching of Trades\n",
    "#the simplest metrics\n",
    "\n",
    "print( '1.Trade Result', summary_data['prof_loss'].sum().astype(float).round(2) )\n",
    "\n",
    "print('\\n2.Profit Factor', (summary_data.loc [ summary_data['prof_loss'] > 0,  ]['prof_loss'].sum().round() /\n",
    "                         abs(summary_data.loc [ summary_data['prof_loss'] < 0,  ]['prof_loss'].sum().round())).round(2)\n",
    "     )\n",
    "\n",
    "print('\\n3.Quantity of trades\\n', summary_data.groupby('pos_neg', as_index = False) \\\n",
    "                                            .agg( { 'pos_neg' : 'count' } ) \\\n",
    "                                            .rename(columns={ 'pos_neg' : 'trades'}, \n",
    "                                                    index = {0 : 'positive',\n",
    "                                                             1 : 'neutral',\n",
    "                                                             2 : 'negative'}) )\n",
    "\n",
    "print('\\n4.Long/Short Trades', \n",
    "      '\\n long', summary_data.loc[ summary_data['side'] == 1 ].count()[0], \n",
    "       summary_data.loc[ summary_data['side'] == 1 ].groupby( 'pos_neg', as_index = False ) \\\n",
    "                                                    .agg( { 'pos_neg' : 'count' } ) \\\n",
    "                                                    .rename(columns={ 'pos_neg' : ''}, \n",
    "                                                            index = {0 : '   positive',\n",
    "                                                                     1 : '   neutral',\n",
    "                                                                     2 : '   negative'}),\n",
    "      '\\n short', summary_data.loc[ summary_data['side'] == -1 ].count()[0],\n",
    "      summary_data.loc[ summary_data['side'] == -1 ].groupby( 'pos_neg', as_index = False ) \\\n",
    "                                                    .agg( { 'pos_neg' : 'count' } ) \\\n",
    "                                                    .rename(columns={ 'pos_neg' : ''}, \n",
    "                                                            index = {0 : '   positive',\n",
    "                                                                     1 : '   neutral',\n",
    "                                                                     2 : '   negative'})\n",
    "     )\n",
    "\n",
    "print('\\n5.Trades by day of the week\\n', summary_data.groupby( ['week_day'], as_index = False) \\\n",
    "            .agg( { 'open' : 'count' } ) \\\n",
    "            .rename(columns={ 'open' : 'trades'}, \n",
    "                    index = {0 : 'Monday',\n",
    "                             1 : 'Tuesday',\n",
    "                             2 : 'Wednesday',\n",
    "                             3 : 'Thursday',\n",
    "                             4 : 'Friday' } )['trades'])\n",
    "        \n",
    "print( summary_data.groupby( ['week_day', 'pos_neg'], as_index = False) \\\n",
    "            .agg( { 'open' : 'count' } ) \\\n",
    "            .rename(columns = { 'open' : 'trades' }) \\\n",
    "            .pivot(index = 'pos_neg' , columns = 'week_day' , values = 'trades') \\\n",
    "            .rename(columns = {0 : 'Monday',\n",
    "                               1 : 'Tuesday',\n",
    "                               2 : 'Wednesday',\n",
    "                               3 : 'Thursday',\n",
    "                               4 : 'Friday' })\n",
    "     )\n",
    "\n",
    "print('\\n6. Trades by hour of day\\n', \n",
    "        summary_data.groupby('hour_trade', as_index = False) \\\n",
    "                    .agg( { 'open' : 'count' } )\\\n",
    "                    .rename(columns = {'open' : 'trades'}) )\n",
    "\n",
    "print( summary_data.groupby( ['hour_trade', 'pos_neg'], as_index = False) \\\n",
    "                    .agg( { 'open' : 'count' } ) \\\n",
    "                    .rename(columns = {'open' : 'trades'}) \\\n",
    "                    .pivot(index = 'pos_neg', columns = 'hour_trade', values = 'trades') \n",
    "     )\n",
    "\n",
    "print('\\n7. Time in the Trades\\n')\n",
    "print('Mean Time in the position\\n', summary_data['pos_time'].describe().iloc[[1,3,7]])\n",
    "print('\\nMean Time in the position of Negative Trades\\n',\n",
    "       summary_data.loc [ summary_data['pos_neg'] == 'neg' ].mean()['pos_time'] )\n",
    "print('Mean Time in the position of Positive Trades\\n',\n",
    "       summary_data.loc [ summary_data['pos_neg'] == 'pos' ].mean()['pos_time'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8e0930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              prof_loss   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.5728\n",
      "Date:                Mon, 05 Sep 2022   Prob (F-statistic):              0.633\n",
      "Time:                        10:49:35   Log-Likelihood:                 844.19\n",
      "No. Observations:                4341   AIC:                            -1680.\n",
      "Df Residuals:                    4337   BIC:                            -1655.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.0012      0.006     -0.188      0.851      -0.014       0.011\n",
      "side           0.0019      0.003      0.620      0.535      -0.004       0.008\n",
      "week_day      -0.0011      0.002     -0.540      0.589      -0.005       0.003\n",
      "hour_trade    -0.0015      0.002     -1.023      0.306      -0.005       0.001\n",
      "==============================================================================\n",
      "Omnibus:                     1116.586   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5553.433\n",
      "Skew:                          -1.146   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.044   Cond. No.                         8.07\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "result = sm.ols(formula = ' prof_loss ~ side + week_day + hour_trade ', data = summary_data).fit()\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
